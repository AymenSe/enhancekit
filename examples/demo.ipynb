{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancekit demo\n",
    "\n",
    "This notebook demonstrates the basic workflow for using `enhancekit` to inspect the\n",
    "available models and run an enhancement pass over one or more distorted images. Place\n",
    "any test inputs inside `examples/images/` before running the cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "from IPython.display import display\n",
    "\n",
    "from enhancekit import list_models, load_model\n",
    "\n",
    "# Ensure the examples folder exists and point to the image directory\n",
    "EXAMPLES_DIR = Path(\"examples\")\n",
    "IMAGES_DIR = EXAMPLES_DIR / \"images\"\n",
    "IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ba574",
   "metadata": {},
   "source": [
    "## Explore the registry\n",
    "\n",
    "Inspect the registered models to decide which variant you want to try. The built-in\n",
    "examples include lightweight identity models that are useful for verifying the\n",
    "pipeline end-to-end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e351954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the registered model identifiers\n",
    "list_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28178b7d",
   "metadata": {},
   "source": [
    "## Prepare an example image\n",
    "\n",
    "If you already placed a distorted image inside `examples/images`, the notebook will\n",
    "pick the first one. Otherwise, it will synthesize a small noisy gradient so you can\n",
    "run the demo without additional assets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_distorted_image() -> Path:\n",
    "    existing: Optional[Path] = next(IMAGES_DIR.glob(\"*.png\"), None)\n",
    "    if existing:\n",
    "        return existing\n",
    "\n",
    "    # Build a simple synthetic test image when no sample is provided\n",
    "    base = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "    xs = np.linspace(0, 1, base.shape[1], dtype=np.float32)\n",
    "    ys = np.linspace(0, 1, base.shape[0], dtype=np.float32)\n",
    "    base[..., 0] = xs  # horizontal gradient\n",
    "    base[..., 1] = ys[:, None]  # vertical gradient\n",
    "    base[..., 2] = 0.2\n",
    "\n",
    "    noise = np.random.normal(scale=0.05, size=base.shape).astype(np.float32)\n",
    "    noisy = np.clip(base + noise, 0.0, 1.0)\n",
    "\n",
    "    image = Image.fromarray((noisy * 255).astype(\"uint8\")).filter(ImageFilter.GaussianBlur(radius=1.5))\n",
    "    out_path = IMAGES_DIR / \"synthetic_distorted.png\"\n",
    "    image.save(out_path)\n",
    "    return out_path\n",
    "\n",
    "\n",
    "example_path = load_distorted_image()\n",
    "print(f\"Using example image: {example_path}\")\n",
    "display(Image.open(example_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a740bb",
   "metadata": {},
   "source": [
    "## Run enhancement\n",
    "\n",
    "Load a model from the registry and run `enhance_image` to generate the enhanced output.\n",
    "You can adjust `device` to use a GPU if one is available and pick any registered model\n",
    "name from the list above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"identity_gain2\", device=\"cpu\", freeze=True)\n",
    "\n",
    "# Enhance a single image\n",
    "result = model.enhance_image(example_path)\n",
    "\n",
    "enhanced_path = IMAGES_DIR / \"enhanced_preview.png\"\n",
    "result.save(enhanced_path)\n",
    "\n",
    "print(f\"Enhanced image saved to: {enhanced_path}\")\n",
    "display(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d94bbe",
   "metadata": {},
   "source": [
    "## Quick Uformer sanity check\n",
    "\n",
    "Initialize a `Uformer` instance using the original configuration values (embed_dim,\n",
    "depths, attention heads, and token settings) while keeping the spatial size small\n",
    "so the forward pass stays lightweight on CPU. This avoids downloading weights and\n",
    "just validates that the architecture executes end-to-end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766dba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from enhancekit.models.uformer import Uformer\n",
    "\n",
    "torch.manual_seed(0)\n",
    "uformer = Uformer(\n",
    "    img_size=64,\n",
    "    embed_dim=32,\n",
    "    depths=[2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "    num_heads=[1, 2, 4, 8, 16, 16, 8, 4, 2],\n",
    "    win_size=8,\n",
    "    token_projection=\"linear\",\n",
    "    token_mlp=\"leff\",\n",
    "    modulator=False,\n",
    "    shift_flag=True,\n",
    ")\n",
    "\n",
    "fake_input = torch.rand(1, 3, 64, 64)\n",
    "uformer.eval()\n",
    "with torch.no_grad():\n",
    "    fake_output = uformer(fake_input)\n",
    "\n",
    "print(f\"Fake input shape: {tuple(fake_input.shape)} -> output shape: {tuple(fake_output.shape)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ba41d",
   "metadata": {},
   "source": [
    "## Batch and folder utilities\n",
    "\n",
    "Enhance an entire folder by reusing the same model. Outputs are written to a sibling\n",
    "`examples/outputs` directory so you can compare them with the originals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaac5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = EXAMPLES_DIR / \"outputs\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Run over every image in the folder\n",
    "output_paths = model.enhance_folder(IMAGES_DIR, output_folder=OUTPUT_DIR)\n",
    "\n",
    "print(f\"Wrote {len(output_paths)} enhanced files to {OUTPUT_DIR}\")\n",
    "for path in output_paths:\n",
    "    display(Image.open(path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
